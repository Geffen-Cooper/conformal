{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.optimize import brentq,root_scalar\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruptions = ['gaussian_noise','impulse_noise','shot_noise','defocus_blur','glass_blur','motion_blur','zoom_blur','snow','frost','fog','brightness','contrast','elastic_transform','jpeg_compression','pixelate']\n",
    "# load the confidence scores\n",
    "clean_embds,clean_labels,clean_preds = torch.load(\"../continual_learning/continual_learning_playground/src/test_time_kd/embds/clean224.pt\")\n",
    "clean_embds128,clean_labels128,clean_preds128 = torch.load(\"../continual_learning/continual_learning_playground/src/test_time_kd/embds/clean128.pt\")\n",
    "corr_embds = []\n",
    "corr_labels = []\n",
    "corr_preds = []\n",
    "corr_embds128 = []\n",
    "corr_labels128 = []\n",
    "corr_preds128 = []\n",
    "corr_embds64 = []\n",
    "corr_labels64 = []\n",
    "corr_preds64 = []\n",
    "for i,corr in enumerate(corruptions):\n",
    "    e,l,p = torch.load(\"../continual_learning/continual_learning_playground/src/test_time_kd/embds/corr224_\"+corr+\".pt\")\n",
    "    e128,l128,p128 = torch.load(\"../continual_learning/continual_learning_playground/src/test_time_kd/embds/corr128_\"+corr+\".pt\")\n",
    "    # e64,l64,p64 = torch.load(\"embds/corr64_\"+corr+\".pt\")\n",
    "    corr_embds.append(e)\n",
    "    corr_labels.append(l)\n",
    "    corr_preds.append(p)\n",
    "    corr_embds128.append(e128)\n",
    "    corr_labels128.append(l128)\n",
    "    corr_preds128.append(p128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "alphas = [0.05,0.15,0.25]\n",
    "rand_idxs = torch.randperm(50000)\n",
    "rand_corr_order = torch.randperm(15)\n",
    "cal_idxs = rand_idxs[:n]\n",
    "val_idxs = rand_idxs[n:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_confs,student_decs = torch.max(clean_preds128,dim=1)\n",
    "teacher_confs,teacher_decs = torch.max(clean_preds,dim=1)\n",
    "\n",
    "student_cal_scores = student_confs[cal_idxs]\n",
    "student_cal_preds = student_decs[cal_idxs]\n",
    "teacher_cal_preds = teacher_decs[cal_idxs]\n",
    "\n",
    "lambda_hats = []\n",
    "\n",
    "for i,alpha in enumerate(alphas):\n",
    "    # zero-one loss\n",
    "    def zo_loss(p_pred_set,t_pred_set):\n",
    "        return (p_pred_set != t_pred_set).float().mean()\n",
    "\n",
    "    # the lambda hat threshold, we want the largest lambda hat that we satisfy the condition\n",
    "    def lamhat_threshold(lam): \n",
    "        p_set = (student_cal_scores >= lam)*student_cal_preds + (student_cal_scores < lam)*teacher_cal_preds\n",
    "        return zo_loss(p_set, teacher_cal_preds) - ((n+1)/n*alpha - 1/(n+1))\n",
    "\n",
    "    lambda_hats.append(brentq(lamhat_threshold, 0, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing\n",
    "* 49000 test points\n",
    "    * 4000 clean, 3000 per corruption\n",
    "* store average risk, acc, and cost over last 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store running stats\n",
    "policy_dec = torch.zeros((len(alphas),len(val_idxs)),dtype=int)\n",
    "policy_pred = torch.zeros((len(alphas),len(val_idxs)),dtype=int)\n",
    "student_pred = torch.zeros(len(val_idxs),dtype=int)\n",
    "teacher_pred = torch.zeros(len(val_idxs),dtype=int)\n",
    "\n",
    "# clean predictions\n",
    "student_val_scores = student_confs[val_idxs]\n",
    "student_val_preds = student_decs[val_idxs]\n",
    "teacher_val_preds = teacher_decs[val_idxs]\n",
    "\n",
    "# try three different alphas\n",
    "for alpha_i,alpha in enumerate(alphas):\n",
    "    # get decision for clean samples (1 = student, 0 = teacher)\n",
    "    policy_dec[alpha_i,:4000] = (student_val_scores[:4000] >= lambda_hats[alpha_i])\n",
    "    policy_pred[alpha_i,:4000] = (student_val_scores[:4000] >= lambda_hats[alpha_i])*student_val_preds[:4000] + \\\n",
    "                                 (student_val_scores[:4000] < lambda_hats[alpha_i])*teacher_val_preds[:4000]\n",
    "    student_pred[:4000] = student_val_preds[:4000]\n",
    "    teacher_pred[:4000] = teacher_val_preds[:4000]\n",
    "\n",
    "    # get decision for each corruption\n",
    "    for corr_i,corruption in enumerate(corruptions):\n",
    "        student_confs_,student_decs_ = torch.max(corr_preds128[rand_corr_order[corr_i]],dim=1)\n",
    "        teacher_confs_,teacher_decs_ = torch.max(corr_preds[rand_corr_order[corr_i]],dim=1)\n",
    "\n",
    "        student_val_scores_ = student_confs_[val_idxs]\n",
    "        student_val_preds_ = student_decs_[val_idxs]\n",
    "        teacher_val_preds_ = teacher_decs_[val_idxs]\n",
    "\n",
    "        # get decision for corrupt samples (1 = student, 0 = teacher)\n",
    "        start = 4000+corr_i*3000\n",
    "        stop = 4000+(corr_i+1)*3000\n",
    "        policy_dec[alpha_i,start:stop] = (student_val_scores_[start:stop] >= lambda_hats[alpha_i])\n",
    "        policy_pred[alpha_i,start:stop] = (student_val_scores_[start:stop] >= lambda_hats[alpha_i])*student_val_preds_[start:stop] + \\\n",
    "                                          (student_val_scores_[start:stop] < lambda_hats[alpha_i])*teacher_val_preds_[start:stop]\n",
    "        student_pred[start:stop] = student_val_preds_[start:stop]\n",
    "        teacher_pred[start:stop] = teacher_val_preds_[start:stop]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49000/49000 [00:10<00:00, 4815.64it/s]\n"
     ]
    }
   ],
   "source": [
    "local_avg_risk = torch.zeros((len(alphas),len(val_idxs)))\n",
    "local_avg_acc = torch.zeros((len(alphas),len(val_idxs)))\n",
    "local_avg_acc_t = torch.zeros(len(val_idxs))\n",
    "local_avg_cost = torch.zeros((len(alphas),len(val_idxs)))\n",
    "avg_risk = torch.zeros(len(alphas))\n",
    "avg_acc = torch.zeros(len(alphas))\n",
    "avg_acc_t = 0\n",
    "avg_cost = torch.zeros(len(alphas))\n",
    "\n",
    "window_size = 1000\n",
    "gt_val = corr_labels[0][val_idxs]\n",
    "\n",
    "for idx,sample in enumerate(tqdm(policy_dec[0])):\n",
    "    start = 0 if idx <= window_size else idx - window_size\n",
    "    stop = idx+1\n",
    "    for alpha_i,alpha in enumerate(alphas):\n",
    "        local_avg_risk[alpha_i,idx] = (policy_pred[alpha_i,start:stop] != teacher_pred[start:stop]).float().mean()\n",
    "        local_avg_acc[alpha_i,idx] = (policy_pred[alpha_i,start:stop] == gt_val[start:stop]).float().mean()\n",
    "        local_avg_acc_t[idx] = (teacher_pred[start:stop] == gt_val[start:stop]).float().mean()\n",
    "        local_avg_cost[alpha_i,idx] = ((policy_dec[alpha_i,start:stop] == 1)*1 + (policy_dec[alpha_i,start:stop] == 0)*10).float().mean()\n",
    "\n",
    "for alpha_i,alpha in enumerate(alphas):\n",
    "    avg_risk[alpha_i] = (policy_pred[alpha_i,:] != teacher_pred[:]).float().mean()\n",
    "    avg_acc[alpha_i] = (policy_pred[alpha_i,:] == gt_val[:]).float().mean()\n",
    "    avg_acc_t = (teacher_pred[:] == gt_val[:]).float().mean()\n",
    "    avg_cost[alpha_i] = ((policy_dec[alpha_i,:] == 1)*1 + (policy_dec[alpha_i,:] == 0)*10).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3,figsize=(22,16))\n",
    "cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "for alpha_i,alpha in enumerate(alphas):\n",
    "    # risk\n",
    "    ax[alpha_i,0].plot(torch.arange(0,len(val_idxs)),local_avg_risk[alpha_i,:],c=cycle[alpha_i],label=\"local empirical risk\")\n",
    "    ax[alpha_i,0].axhline(avg_risk[alpha_i],c=cycle[alpha_i],linestyle=\"--\",label=\"empirical risk\")\n",
    "    ax[alpha_i,0].axhline(alpha,c=cycle[alpha_i],label=r'$\\alpha=$'+str(alpha),alpha=0.5)\n",
    "    ax[alpha_i,0].set_title(\"Risk Coverage\")\n",
    "    ax[alpha_i,0].set_xlabel(\"Sample Index\")\n",
    "    ax[alpha_i,0].set_ylabel(r'$\\hat{R}(\\lambda)$ (Empirical Risk)')\n",
    "    for i in range(15):\n",
    "        ax[alpha_i,0].axvline(4000+i*3000,c='k',alpha=0.25)\n",
    "    # accuracy\n",
    "    ax[alpha_i,1].plot(torch.arange(0,len(val_idxs)),local_avg_acc[alpha_i,:],c=cycle[alpha_i],label=\"local empirical accuracy\")\n",
    "    ax[alpha_i,1].plot(torch.arange(0,len(val_idxs)),local_avg_acc_t[:],c='k',label=\"local teacher accuracy\",alpha=0.5)\n",
    "    ax[alpha_i,1].fill_between(torch.arange(0,len(val_idxs)),(1-alpha)*local_avg_acc_t,local_avg_acc_t,color='k',alpha=0.25,label=str(1-alpha)+\"% of local empirical teacher accuracy\")\n",
    "    ax[alpha_i,1].axhline(avg_acc[alpha_i],c=cycle[alpha_i],linestyle=\"--\",label=\"average accuracy\")\n",
    "    ax[alpha_i,1].axhline(avg_acc_t,c='k',alpha=0.5,label=\"average teacher accuracy\")\n",
    "    ax[alpha_i,1].set_title(\"Accuracy Coverage\")\n",
    "    ax[alpha_i,1].set_xlabel(\"Sample Index\")\n",
    "    ax[alpha_i,1].set_ylabel(\"Accuracy\")\n",
    "    for i in range(15):\n",
    "        ax[alpha_i,1].axvline(4000+i*3000,c='k',alpha=0.25)\n",
    "    # maybe add fill between on total average?\n",
    "    # cost\n",
    "    ax[alpha_i,2].plot(torch.arange(0,len(val_idxs)),local_avg_cost[alpha_i,:],c=cycle[alpha_i],label=\"local empirical cost\")\n",
    "    ax[alpha_i,2].axhline(avg_cost[alpha_i],c=cycle[alpha_i],linestyle=\"--\",label=\"average cost\")\n",
    "    ax[alpha_i,2].set_title(r'Cost Coverage: $\\hat{\\lambda}=$'+str(round(lambda_hats[alpha_i],2)))\n",
    "    ax[alpha_i,2].set_xlabel(\"Sample Index\")\n",
    "    ax[alpha_i,2].set_ylabel(\"Cost\")\n",
    "    ax[alpha_i,2].set_ylim([0,10])\n",
    "    for i in range(15):\n",
    "        ax[alpha_i,2].axvline(4000+i*3000,c='k',alpha=0.25)\n",
    "\n",
    "    ax[alpha_i,0].legend(bbox_to_anchor=(0.7,0.8))\n",
    "    ax[alpha_i,1].legend(bbox_to_anchor=(0.7,0.8))\n",
    "    ax[alpha_i,2].legend(bbox_to_anchor=(0.7,0.8))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
